{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "976ed8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64fa9905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[0.7119, 0.6279, 0.1930, 0.7386, 0.3676, 0.6129, 0.5556, 0.5599]],\n",
      "\n",
      "          [[0.8923, 0.5695, 0.9922, 0.2585, 0.3055, 0.8037, 0.7164, 0.8240]],\n",
      "\n",
      "          [[0.1494, 0.3997, 0.9167, 0.7235, 0.3855, 0.9394, 0.7659, 0.2134]]],\n",
      "\n",
      "\n",
      "         [[[0.6122, 0.8779, 0.3864, 0.6881, 0.2117, 0.9595, 0.4316, 0.6140]],\n",
      "\n",
      "          [[0.2266, 0.1357, 0.6260, 0.8139, 0.8025, 0.0456, 0.7742, 0.6268]],\n",
      "\n",
      "          [[0.3385, 0.1099, 0.2835, 0.4758, 0.6905, 0.4603, 0.9638, 0.4982]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0.8696, 0.7884, 0.3562, 0.8750, 0.9478, 0.9789, 0.2254, 0.2384]],\n",
      "\n",
      "          [[0.9566, 0.0481, 0.5150, 0.4613, 0.8827, 0.6050, 0.4009, 0.3346]],\n",
      "\n",
      "          [[0.1678, 0.8758, 0.7838, 0.5718, 0.8089, 0.7214, 0.9390, 0.0506]]],\n",
      "\n",
      "\n",
      "         [[[0.7544, 0.4244, 0.1998, 0.3370, 0.6617, 0.3630, 0.5426, 0.3742]],\n",
      "\n",
      "          [[0.1352, 0.3322, 0.2969, 0.1964, 0.5656, 0.0695, 0.7811, 0.0730]],\n",
      "\n",
      "          [[0.7536, 0.9003, 0.1899, 0.9563, 0.4342, 0.5585, 0.8518, 0.8401]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0.5663, 0.5128, 0.4946, 0.2315, 0.8769, 0.5394, 0.6750, 0.2521]],\n",
      "\n",
      "          [[0.0260, 0.0093, 0.8793, 0.9542, 0.7616, 0.0204, 0.4035, 0.9329]],\n",
      "\n",
      "          [[0.8145, 0.9904, 0.2412, 0.4732, 0.5029, 0.1945, 0.0123, 0.2482]]],\n",
      "\n",
      "\n",
      "         [[[0.1632, 0.9629, 0.8848, 0.9929, 0.2593, 0.0943, 0.9158, 0.0771]],\n",
      "\n",
      "          [[0.9542, 0.4635, 0.4134, 0.8685, 0.1882, 0.2847, 0.0626, 0.6372]],\n",
      "\n",
      "          [[0.0379, 0.1309, 0.6020, 0.5649, 0.7671, 0.9666, 0.1990, 0.7145]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0.1984, 0.8865, 0.5065, 0.0542, 0.2017, 0.1005, 0.3046, 0.8151]],\n",
      "\n",
      "          [[0.7224, 0.8592, 0.6599, 0.8836, 0.2296, 0.6484, 0.2551, 0.8865]],\n",
      "\n",
      "          [[0.4273, 0.0526, 0.9580, 0.7828, 0.9596, 0.4115, 0.8848, 0.1015]]],\n",
      "\n",
      "\n",
      "         [[[0.8647, 0.2409, 0.6316, 0.5095, 0.6888, 0.7248, 0.7222, 0.2510]],\n",
      "\n",
      "          [[0.3236, 0.4573, 0.0167, 0.8331, 0.8451, 0.4075, 0.9720, 0.8271]],\n",
      "\n",
      "          [[0.1966, 0.3560, 0.5431, 0.8543, 0.4888, 0.3809, 0.9903, 0.9769]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0.7602, 0.2748, 0.4942, 0.1041, 0.4232, 0.4225, 0.2861, 0.0524]],\n",
      "\n",
      "          [[0.6470, 0.2480, 0.2213, 0.3087, 0.1641, 0.1232, 0.3697, 0.9407]],\n",
      "\n",
      "          [[0.9516, 0.4874, 0.2921, 0.9525, 0.9406, 0.7301, 0.4323, 0.9676]]],\n",
      "\n",
      "\n",
      "         [[[0.1007, 0.3395, 0.5550, 0.4254, 0.0543, 0.4538, 0.1732, 0.2541]],\n",
      "\n",
      "          [[0.9120, 0.9455, 0.3958, 0.8400, 0.5072, 0.4234, 0.0684, 0.4588]],\n",
      "\n",
      "          [[0.5770, 0.6753, 0.8353, 0.3182, 0.2005, 0.9977, 0.7545, 0.7751]]]]])\n"
     ]
    }
   ],
   "source": [
    "T = torch.rand((5,2,3,1,8))\n",
    "#tensors can be of any shape in torch\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca2a0b8",
   "metadata": {},
   "source": [
    "# Speechbrain implementation : \n",
    "\n",
    "No full complex activation functions for quat and complex, \n",
    "must apply split activation functions on the different components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9119c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 20, 16])\n"
     ]
    }
   ],
   "source": [
    "from speechbrain.nnet.complex_networks.c_CNN import CConv1d, CConv2d\n",
    "\n",
    "# to mimic the output of sftf \n",
    "# 4 examples, 20 time windows, 64 \"features\"\n",
    "# also works for cconv2d so we can transform any networks \n",
    "# with quat and complex layers\n",
    "T = torch.rand((4, 20, 64))\n",
    "\n",
    "cnn_1d = CConv1d(input_shape = T.shape, out_channels=8, kernel_size=3)\n",
    "\n",
    "out_tensor = cnn_1d(T)\n",
    "print(out_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fdb7645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d757061d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:46<00:00, 3.70MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c2ae295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ba9f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01d58c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5348b1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.220\n",
      "[1,  4000] loss: 1.995\n",
      "[1,  6000] loss: 1.758\n",
      "[1,  8000] loss: 1.632\n",
      "[1, 10000] loss: 1.560\n",
      "[1, 12000] loss: 1.474\n",
      "[2,  2000] loss: 1.414\n",
      "[2,  4000] loss: 1.389\n",
      "[2,  6000] loss: 1.355\n",
      "[2,  8000] loss: 1.341\n",
      "[2, 10000] loss: 1.297\n",
      "[2, 12000] loss: 1.294\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "574d1af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4286df37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3baad91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 52 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e99e129",
   "metadata": {},
   "source": [
    "# Toy example CNN\n",
    "\n",
    "Now we implement a CNN with quaternion operations \n",
    "\n",
    "Torch doesn't support Quaternion operations so I'll do it\n",
    "with speechbrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90577897",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf35904",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'quaternion_layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mquaternion_layers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QuaternionConv, QuaternionLinear\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'quaternion_layers'"
     ]
    }
   ],
   "source": [
    "from quaternion_layers import QuaternionConv, QuaternionLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6accc8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfd81c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # ok well permuted \n",
    "        inputs = inputs.permute(0,2,3,1)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
